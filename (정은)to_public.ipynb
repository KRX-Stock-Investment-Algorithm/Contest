{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xf but this version of numpy is 0xe",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;31mRuntimeError\u001b[0m: module compiled against API version 0xf but this version of numpy is 0xe"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xf but this version of numpy is 0xe",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;31mRuntimeError\u001b[0m: module compiled against API version 0xf but this version of numpy is 0xe"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core._multiarray_umath failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy.core._multiarray_umath failed to import"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.umath failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.umath failed to import"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xf but this version of numpy is 0xe",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;31mRuntimeError\u001b[0m: module compiled against API version 0xf but this version of numpy is 0xe"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core._multiarray_umath failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy.core._multiarray_umath failed to import"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.umath failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.umath failed to import"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xf but this version of numpy is 0xe",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;31mRuntimeError\u001b[0m: module compiled against API version 0xf but this version of numpy is 0xe"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core._multiarray_umath failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy.core._multiarray_umath failed to import"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.umath failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.umath failed to import"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Unable to convert function return value to a Python type! The signature was\n\t() -> handle",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\minsu\\Desktop\\contest\\dacon_주가예측경진대회\\to_public.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/minsu/Desktop/contest/dacon_%EC%A3%BC%EA%B0%80%EC%98%88%EC%B8%A1%EA%B2%BD%EC%A7%84%EB%8C%80%ED%9A%8C/to_public.ipynb#W0sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/minsu/Desktop/contest/dacon_%EC%A3%BC%EA%B0%80%EC%98%88%EC%B8%A1%EA%B2%BD%EC%A7%84%EB%8C%80%ED%9A%8C/to_public.ipynb#W0sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m warnings\u001b[39m.\u001b[39mfilterwarnings(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/minsu/Desktop/contest/dacon_%EC%A3%BC%EA%B0%80%EC%98%88%EC%B8%A1%EA%B2%BD%EC%A7%84%EB%8C%80%ED%9A%8C/to_public.ipynb#W0sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/minsu/Desktop/contest/dacon_%EC%A3%BC%EA%B0%80%EC%98%88%EC%B8%A1%EA%B2%BD%EC%A7%84%EB%8C%80%ED%9A%8C/to_public.ipynb#W0sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m Dense, LSTM, Dropout\n",
      "File \u001b[1;32mc:\\Users\\minsu\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py:38\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_typing\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtools\u001b[39;00m \u001b[39mimport\u001b[39;00m module_util \u001b[39mas\u001b[39;00m _module_util\n\u001b[0;32m     39\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlazy_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m LazyLoader \u001b[39mas\u001b[39;00m _LazyLoader\n\u001b[0;32m     41\u001b[0m \u001b[39m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\minsu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py:37\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[39m# We aim to keep this file minimal and ideally remove completely.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[39m# If you are adding a new file with @tf_export decorators,\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[39m# import it in modules_with_exports.py instead.\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \n\u001b[0;32m     33\u001b[0m \u001b[39m# go/tf-wildcard-import\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[39m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m pywrap_tensorflow \u001b[39mas\u001b[39;00m _pywrap_tensorflow\n\u001b[1;32m---> 37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m context\n\u001b[0;32m     39\u001b[0m \u001b[39m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[39m# Bring in subpackages.\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\minsu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:36\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mclient\u001b[39;00m \u001b[39mimport\u001b[39;00m pywrap_tf_session\n\u001b[0;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m cancellation\n\u001b[1;32m---> 36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m execute\n\u001b[0;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m executor\n\u001b[0;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m monitoring\n",
      "File \u001b[1;32mc:\\Users\\minsu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:21\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m pywrap_tfe\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m core\n\u001b[1;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m dtypes\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m tensor_conversion_registry\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m tensor_shape\n",
      "File \u001b[1;32mc:\\Users\\minsu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:38\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtsl\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m pywrap_bfloat16\n\u001b[0;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m cpp_shape_inference_pb2\n\u001b[1;32m---> 38\u001b[0m _np_bfloat16 \u001b[39m=\u001b[39m pywrap_bfloat16\u001b[39m.\u001b[39;49mbfloat16_type()\n\u001b[0;32m     39\u001b[0m _np_float8_e4m3fn \u001b[39m=\u001b[39m _pywrap_float8\u001b[39m.\u001b[39mTF_float8_e4m3fn_type()\n\u001b[0;32m     40\u001b[0m _np_float8_e5m2 \u001b[39m=\u001b[39m _pywrap_float8\u001b[39m.\u001b[39mTF_float8_e5m2_type()\n",
      "\u001b[1;31mTypeError\u001b[0m: Unable to convert function return value to a Python type! The signature was\n\t() -> handle"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.13.0-cp39-cp39-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.13.0\n",
      "  Downloading tensorflow_intel-2.13.0-cp39-cp39-win_amd64.whl (276.5 MB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\minsu\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.12.1)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-16.0.6-py2.py3-none-win_amd64.whl (24.4 MB)\n",
      "Requirement already satisfied: packaging in c:\\users\\minsu\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\users\\minsu\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.1.1)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting keras<2.14,>=2.13.1\n",
      "  Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "Collecting flatbuffers>=23.1.21\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\minsu\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.42.0)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Collecting tensorboard<2.14,>=2.13\n",
      "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Collecting numpy<=1.24.3,>=1.22\n",
      "  Downloading numpy-1.24.3-cp39-cp39-win_amd64.whl (14.9 MB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\minsu\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\minsu\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (61.2.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-4.23.4-cp39-cp39-win_amd64.whl (422 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\minsu\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.6.0)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Collecting tensorflow-estimator<2.14,>=2.13.0\n",
      "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\minsu\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\minsu\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\minsu\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.0.3)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\minsu\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.33.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\minsu\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.3.4)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.56.2-cp39-cp39-win_amd64.whl (4.2 MB)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\minsu\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\minsu\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\minsu\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.2.8)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\minsu\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\minsu\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\minsu\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\minsu\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\minsu\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.3)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\minsu\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.13.0->tensorflow) (3.0.4)\n",
      "Installing collected packages: oauthlib, requests-oauthlib, google-auth, tensorboard-data-server, protobuf, numpy, grpcio, google-auth-oauthlib, absl-py, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, libclang, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: google-auth\n",
      "    Found existing installation: google-auth 1.33.0\n",
      "    Uninstalling google-auth-1.33.0:\n",
      "      Successfully uninstalled google-auth-1.33.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.1\n",
      "    Uninstalling protobuf-3.19.1:\n",
      "      Successfully uninstalled protobuf-3.19.1\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.5\n",
      "    Uninstalling numpy-1.21.5:\n",
      "      Successfully uninstalled numpy-1.21.5\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.42.0\n",
      "    Uninstalling grpcio-1.42.0:\n",
      "      Successfully uninstalled grpcio-1.42.0\n",
      "Successfully installed absl-py-1.4.0 astunparse-1.6.3 flatbuffers-23.5.26 gast-0.4.0 google-auth-2.22.0 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.56.2 keras-2.13.1 libclang-16.0.6 numpy-1.24.3 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-4.23.4 requests-oauthlib-1.3.1 tensorboard-2.13.0 tensorboard-data-server-0.7.1 tensorflow-2.13.0 tensorflow-estimator-2.13.0 tensorflow-intel-2.13.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "daal4py 2021.5.0 requires daal==2021.4.0, which is not installed.\n",
      "scipy 1.7.3 requires numpy<1.23.0,>=1.16.5, but you have numpy 1.24.3 which is incompatible.\n",
      "numba 0.55.1 requires numpy<1.22,>=1.18, but you have numpy 1.24.3 which is incompatible.\n",
      "google-cloud-storage 1.31.0 requires google-auth<2.0dev,>=1.11.0, but you have google-auth 2.22.0 which is incompatible.\n",
      "google-cloud-core 1.7.1 requires google-auth<2.0dev,>=1.24.0, but you have google-auth 2.22.0 which is incompatible.\n",
      "google-api-core 1.25.1 requires google-auth<2.0dev,>=1.21.1, but you have google-auth 2.22.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.21.6\n",
      "  Downloading numpy-1.21.6-cp39-cp39-win_amd64.whl (14.0 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.3\n",
      "    Uninstalling numpy-1.24.3:\n",
      "      Successfully uninstalled numpy-1.24.3\n",
      "Successfully installed numpy-1.21.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "daal4py 2021.5.0 requires daal==2021.4.0, which is not installed.\n",
      "tensorflow-intel 2.13.0 requires numpy<=1.24.3,>=1.22, but you have numpy 1.21.6 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "! pip install numpy==1.21.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드 고정\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(42) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>일자</th>\n",
       "      <th>종목코드</th>\n",
       "      <th>종목명</th>\n",
       "      <th>거래량</th>\n",
       "      <th>시가</th>\n",
       "      <th>고가</th>\n",
       "      <th>저가</th>\n",
       "      <th>종가</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20210601</td>\n",
       "      <td>A060310</td>\n",
       "      <td>3S</td>\n",
       "      <td>166690</td>\n",
       "      <td>2890</td>\n",
       "      <td>2970</td>\n",
       "      <td>2885</td>\n",
       "      <td>2920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20210601</td>\n",
       "      <td>A095570</td>\n",
       "      <td>AJ네트웍스</td>\n",
       "      <td>63836</td>\n",
       "      <td>5860</td>\n",
       "      <td>5940</td>\n",
       "      <td>5750</td>\n",
       "      <td>5780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20210601</td>\n",
       "      <td>A006840</td>\n",
       "      <td>AK홀딩스</td>\n",
       "      <td>103691</td>\n",
       "      <td>35500</td>\n",
       "      <td>35600</td>\n",
       "      <td>34150</td>\n",
       "      <td>34400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20210601</td>\n",
       "      <td>A054620</td>\n",
       "      <td>APS</td>\n",
       "      <td>462544</td>\n",
       "      <td>14600</td>\n",
       "      <td>14950</td>\n",
       "      <td>13800</td>\n",
       "      <td>14950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20210601</td>\n",
       "      <td>A265520</td>\n",
       "      <td>AP시스템</td>\n",
       "      <td>131987</td>\n",
       "      <td>29150</td>\n",
       "      <td>29150</td>\n",
       "      <td>28800</td>\n",
       "      <td>29050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987995</th>\n",
       "      <td>20230530</td>\n",
       "      <td>A189980</td>\n",
       "      <td>흥국에프엔비</td>\n",
       "      <td>272284</td>\n",
       "      <td>3005</td>\n",
       "      <td>3035</td>\n",
       "      <td>2955</td>\n",
       "      <td>2980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987996</th>\n",
       "      <td>20230530</td>\n",
       "      <td>A000540</td>\n",
       "      <td>흥국화재</td>\n",
       "      <td>50218</td>\n",
       "      <td>3250</td>\n",
       "      <td>3255</td>\n",
       "      <td>3195</td>\n",
       "      <td>3215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987997</th>\n",
       "      <td>20230530</td>\n",
       "      <td>A003280</td>\n",
       "      <td>흥아해운</td>\n",
       "      <td>130664</td>\n",
       "      <td>1344</td>\n",
       "      <td>1395</td>\n",
       "      <td>1340</td>\n",
       "      <td>1370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987998</th>\n",
       "      <td>20230530</td>\n",
       "      <td>A037440</td>\n",
       "      <td>희림</td>\n",
       "      <td>141932</td>\n",
       "      <td>9170</td>\n",
       "      <td>9260</td>\n",
       "      <td>9170</td>\n",
       "      <td>9200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987999</th>\n",
       "      <td>20230530</td>\n",
       "      <td>A238490</td>\n",
       "      <td>힘스</td>\n",
       "      <td>2611843</td>\n",
       "      <td>6410</td>\n",
       "      <td>8220</td>\n",
       "      <td>6300</td>\n",
       "      <td>8220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>988000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              일자     종목코드     종목명      거래량     시가     고가     저가     종가\n",
       "0       20210601  A060310      3S   166690   2890   2970   2885   2920\n",
       "1       20210601  A095570  AJ네트웍스    63836   5860   5940   5750   5780\n",
       "2       20210601  A006840   AK홀딩스   103691  35500  35600  34150  34400\n",
       "3       20210601  A054620     APS   462544  14600  14950  13800  14950\n",
       "4       20210601  A265520   AP시스템   131987  29150  29150  28800  29050\n",
       "...          ...      ...     ...      ...    ...    ...    ...    ...\n",
       "987995  20230530  A189980  흥국에프엔비   272284   3005   3035   2955   2980\n",
       "987996  20230530  A000540    흥국화재    50218   3250   3255   3195   3215\n",
       "987997  20230530  A003280    흥아해운   130664   1344   1395   1340   1370\n",
       "987998  20230530  A037440      희림   141932   9170   9260   9170   9200\n",
       "987999  20230530  A238490      힘스  2611843   6410   8220   6300   8220\n",
       "\n",
       "[988000 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('./train.csv')\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\minsu\\Desktop\\contest\\dacon_주가예측경진대회\\to_public.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/minsu/Desktop/contest/dacon_%EC%A3%BC%EA%B0%80%EC%98%88%EC%B8%A1%EA%B2%BD%EC%A7%84%EB%8C%80%ED%9A%8C/to_public.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m final_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39m종목코드\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfinal_return\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/minsu/Desktop/contest/dacon_%EC%A3%BC%EA%B0%80%EC%98%88%EC%B8%A1%EA%B2%BD%EC%A7%84%EB%8C%80%ED%9A%8C/to_public.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# train 데이터에 존재하는 독립적인 종목코드 추출\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/minsu/Desktop/contest/dacon_%EC%A3%BC%EA%B0%80%EC%98%88%EC%B8%A1%EA%B2%BD%EC%A7%84%EB%8C%80%ED%9A%8C/to_public.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m unique_codes \u001b[39m=\u001b[39m train[\u001b[39m'\u001b[39m\u001b[39m종목코드\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39munique()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/minsu/Desktop/contest/dacon_%EC%A3%BC%EA%B0%80%EC%98%88%EC%B8%A1%EA%B2%BD%EC%A7%84%EB%8C%80%ED%9A%8C/to_public.ipynb#W3sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m code \u001b[39min\u001b[39;00m tqdm(unique_codes):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/minsu/Desktop/contest/dacon_%EC%A3%BC%EA%B0%80%EC%98%88%EC%B8%A1%EA%B2%BD%EC%A7%84%EB%8C%80%ED%9A%8C/to_public.ipynb#W3sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m#code = \"A103840\"\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/minsu/Desktop/contest/dacon_%EC%A3%BC%EA%B0%80%EC%98%88%EC%B8%A1%EA%B2%BD%EC%A7%84%EB%8C%80%ED%9A%8C/to_public.ipynb#W3sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# # 이동평균선 간격 데이터 생성\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/minsu/Desktop/contest/dacon_%EC%A3%BC%EA%B0%80%EC%98%88%EC%B8%A1%EA%B2%BD%EC%A7%84%EB%8C%80%ED%9A%8C/to_public.ipynb#W3sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     train_close \u001b[39m=\u001b[39m train[train[\u001b[39m'\u001b[39m\u001b[39m종목코드\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m code][[\u001b[39m'\u001b[39m\u001b[39m종목코드\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39m일자\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m종가\u001b[39m\u001b[39m'\u001b[39m]]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "#### 0725 ver --- 이거로 진행\n",
    "\n",
    "# 저장할 데이터 프레임\n",
    "final_df = pd.DataFrame(columns=['종목코드', 'final_return'])\n",
    "\n",
    "# train 데이터에 존재하는 독립적인 종목코드 추출\n",
    "unique_codes = train['종목코드'].unique()\n",
    "\n",
    "for code in tqdm(unique_codes):\n",
    "#code = \"A103840\"\n",
    "# # 이동평균선 간격 데이터 생성\n",
    "    train_close = train[train['종목코드'] == code][['종목코드','일자', '종가']]\n",
    "    train_close['일자'] = pd.to_datetime(train_close['일자'], format='%Y%m%d')\n",
    "    train_close.set_index('일자', inplace=True)\n",
    "\n",
    "    # 이동평균선 (5/10/20/60)\n",
    "    train_close[\"5평균\"] = train_close['종가'].rolling(window=5).mean()\n",
    "    train_close[\"10평균\"] = train_close['종가'].rolling(window=10).mean()\n",
    "    train_close[\"20평균\"] = train_close['종가'].rolling(window=20).mean()\n",
    "    train_close[\"60평균\"] = train_close['종가'].rolling(window=60).mean()\n",
    "\n",
    "    # 등락폭\n",
    "    #train_close[\"shift\"] = train_close[\"종가\"].shift(1)\n",
    "    #train_close[\"등락폭\"] = (train_close[\"종가\"] - train_close[\"shift\"])\n",
    "    #train_close[\"등락비율\"] = ((train_close[\"종가\"] - train_close[\"shift\"])/train_close[\"shift\"])\n",
    "    #train_close.drop(\"shift\", axis=1,inplace=True)   \n",
    "    \n",
    "    #이동평균선 NaN 값 삭제\n",
    "    train_close.dropna(axis=0,inplace=True)\n",
    "\n",
    "    # 추세선 내부 간격 함수\n",
    "    # 1 _ 5평균 - 10평균\n",
    "    train_close['5_10평균'] = train_close[\"5평균\"] - train_close[\"10평균\"]\n",
    "\n",
    "    # 2 _ 5평균 - 20평균\n",
    "    #train_close['5_20평균'] = train_close[\"5평균\"]-train_close[\"20평균\"]\n",
    "    \n",
    "    # 3 _ 5평균 - 60평균\n",
    "    #train_close['5_60평균'] = train_close[\"5평균\"]-train_close[\"60평균\"]\n",
    "    \n",
    "    # 4 _ 10평균 - 20평균\n",
    "    #train_close['10_20평균'] = train_close[\"10평균\"]-train_close[\"20평균\"]\n",
    "\n",
    "    # 5 _ 10평균 - 60평균\n",
    "    #train_close['10_60평균'] = train_close[\"10평균\"]-train_close[\"60평균\"]\n",
    "\n",
    "    # 6 _ 20평균 - 60평균\n",
    "    #train_close['20_60평균'] = train_close[\"20평균\"]-train_close[\"60평균\"]\n",
    "\n",
    "    ####### train / test 분리\n",
    "\n",
    "\n",
    "    train_size = int(len(data_y) * 0.7)\n",
    "    train_X = np.array(data_X[0 : train_size])\n",
    "    train_y = np.array(data_y[0 : train_size])\n",
    "\n",
    "    test_size = len(data_y) - train_size\n",
    "    test_X = np.array(data_X[train_size : len(data_X)])\n",
    "    test_y = np.array(data_y[train_size : len(data_y)])\n",
    "\n",
    "    print('훈련 데이터의 크기 :', train_X.shape, train_y.shape)\n",
    "    print('테스트 데이터의 크기 :', test_X.shape, test_y.shape)\n",
    "\n",
    "    ## 표준화 + 모델 진행\n",
    "    # StandardScaler객체 생성\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    #scaler용 input 생성\n",
    "    input = train_close[['5_10평균']]\n",
    "\n",
    "    # StandardScaler 로 데이터 셋 변환. fit( ) 과 transform( ) 호출.  \n",
    "    scaler.fit(input)\n",
    "    train_scaled = scaler.transform(input)\n",
    "    train_close['5_10평균'][train_close['종목코드']==code] = train_scaled\n",
    "\n",
    "    # 변수의 가중치 화\n",
    "    tc = train_close['5_10평균']\n",
    "\n",
    "    # 모델 선언, 학습 및 추론\n",
    "    model = ARIMA(tc, order=(2, 1, 2))\n",
    "    model_fit = model.fit()\n",
    "    predictions = model_fit.forecast(steps=15) # 향후 15개의 거래일에 대해서 예측\n",
    "\n",
    "    # 최종 예측치 평균\n",
    "    #final_return = (predictions.iloc[-1] - predictions.iloc[0]) / predictions.iloc[0]\n",
    "    final_return = np.mean(predictions)\n",
    "    \n",
    "    # 최종 데이터프레임\n",
    "    final_df = final_df.append({'종목코드': code, 'final_return': final_return}, ignore_index=True)\n",
    "\n",
    "\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.08188499423395078], [0.33765899533891747], [0.4683366314353846], [0.5852587268901184], [0.7090585926657189], [0.6334031191361853], [0.3789256172641176], [0.2963923734137173], [0.22073689988418368], [0.09693703410858323], [0.15883696699638347], [0.2963923734137173], [0.37204784694325094], [0.3170256843763174], [1.156113663522054]] -> [3015]\n",
      "전체 데이터의 크기 : 420 420\n",
      "훈련 데이터의 크기 : (336, 15, 1) (336, 1)\n",
      "테스트 데이터의 크기 : (84, 15, 1) (84, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Unable to convert function return value to a Python type! The signature was\n\t() -> handle",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\minsu\\Desktop\\contest\\dacon_주가예측경진대회\\to_public.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/minsu/Desktop/contest/dacon_%EC%A3%BC%EA%B0%80%EC%98%88%EC%B8%A1%EA%B2%BD%EC%A7%84%EB%8C%80%ED%9A%8C/to_public.ipynb#W4sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m테스트 데이터의 크기 :\u001b[39m\u001b[39m'\u001b[39m, test_X\u001b[39m.\u001b[39mshape, test_y\u001b[39m.\u001b[39mshape)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/minsu/Desktop/contest/dacon_%EC%A3%BC%EA%B0%80%EC%98%88%EC%B8%A1%EA%B2%BD%EC%A7%84%EB%8C%80%ED%9A%8C/to_public.ipynb#W4sZmlsZQ%3D%3D?line=101'>102</a>\u001b[0m \u001b[39m# 모델 학습\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/minsu/Desktop/contest/dacon_%EC%A3%BC%EA%B0%80%EC%98%88%EC%B8%A1%EA%B2%BD%EC%A7%84%EB%8C%80%ED%9A%8C/to_public.ipynb#W4sZmlsZQ%3D%3D?line=102'>103</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/minsu/Desktop/contest/dacon_%EC%A3%BC%EA%B0%80%EC%98%88%EC%B8%A1%EA%B2%BD%EC%A7%84%EB%8C%80%ED%9A%8C/to_public.ipynb#W4sZmlsZQ%3D%3D?line=103'>104</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m Dense, LSTM, Dropout\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/minsu/Desktop/contest/dacon_%EC%A3%BC%EA%B0%80%EC%98%88%EC%B8%A1%EA%B2%BD%EC%A7%84%EB%8C%80%ED%9A%8C/to_public.ipynb#W4sZmlsZQ%3D%3D?line=105'>106</a>\u001b[0m model \u001b[39m=\u001b[39m Sequential()\n",
      "File \u001b[1;32mc:\\Users\\minsu\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py:38\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_typing\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtools\u001b[39;00m \u001b[39mimport\u001b[39;00m module_util \u001b[39mas\u001b[39;00m _module_util\n\u001b[0;32m     39\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlazy_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m LazyLoader \u001b[39mas\u001b[39;00m _LazyLoader\n\u001b[0;32m     41\u001b[0m \u001b[39m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\minsu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py:37\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[39m# We aim to keep this file minimal and ideally remove completely.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[39m# If you are adding a new file with @tf_export decorators,\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[39m# import it in modules_with_exports.py instead.\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \n\u001b[0;32m     33\u001b[0m \u001b[39m# go/tf-wildcard-import\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[39m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m pywrap_tensorflow \u001b[39mas\u001b[39;00m _pywrap_tensorflow\n\u001b[1;32m---> 37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m context\n\u001b[0;32m     39\u001b[0m \u001b[39m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[39m# Bring in subpackages.\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\minsu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:36\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mclient\u001b[39;00m \u001b[39mimport\u001b[39;00m pywrap_tf_session\n\u001b[0;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m cancellation\n\u001b[1;32m---> 36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m execute\n\u001b[0;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m executor\n\u001b[0;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m monitoring\n",
      "File \u001b[1;32mc:\\Users\\minsu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:21\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m pywrap_tfe\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m core\n\u001b[1;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m dtypes\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m tensor_conversion_registry\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m tensor_shape\n",
      "File \u001b[1;32mc:\\Users\\minsu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:38\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtsl\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m pywrap_bfloat16\n\u001b[0;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m cpp_shape_inference_pb2\n\u001b[1;32m---> 38\u001b[0m _np_bfloat16 \u001b[39m=\u001b[39m pywrap_bfloat16\u001b[39m.\u001b[39;49mbfloat16_type()\n\u001b[0;32m     39\u001b[0m _np_float8_e4m3fn \u001b[39m=\u001b[39m _pywrap_float8\u001b[39m.\u001b[39mTF_float8_e4m3fn_type()\n\u001b[0;32m     40\u001b[0m _np_float8_e5m2 \u001b[39m=\u001b[39m _pywrap_float8\u001b[39m.\u001b[39mTF_float8_e5m2_type()\n",
      "\u001b[1;31mTypeError\u001b[0m: Unable to convert function return value to a Python type! The signature was\n\t() -> handle"
     ]
    }
   ],
   "source": [
    "#### 0727 ver --- LSTM 이걸로 진행\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "\n",
    "# 저장할 데이터 프레임\n",
    "final_df = pd.DataFrame(columns=['종목코드', 'final_return'])\n",
    "\n",
    "# train 데이터에 존재하는 독립적인 종목코드 추출\n",
    "unique_codes = train['종목코드'].unique()\n",
    "\n",
    "for code in tqdm(unique_codes):\n",
    "#code = \"A103840\"\n",
    "# # 이동평균선 간격 데이터 생성\n",
    "    train_close = train[train['종목코드'] == code][['종목코드','일자', '종가']]\n",
    "    train_close['일자'] = pd.to_datetime(train_close['일자'], format='%Y%m%d')\n",
    "    train_close.set_index('일자', inplace=True)\n",
    "\n",
    "    # 이동평균선 (5/10/20/60)\n",
    "    train_close[\"5평균\"] = train_close['종가'].rolling(window=5).mean()\n",
    "    train_close[\"10평균\"] = train_close['종가'].rolling(window=10).mean()\n",
    "    train_close[\"20평균\"] = train_close['종가'].rolling(window=20).mean()\n",
    "    train_close[\"60평균\"] = train_close['종가'].rolling(window=60).mean()\n",
    "    \n",
    "    #이동평균선 NaN 값 삭제\n",
    "    train_close.dropna(axis=0,inplace=True)\n",
    "\n",
    "    # 추세선 내부 간격 함수\n",
    "    # 1 _ 5평균 - 10평균\n",
    "    train_close['5_10평균'] = train_close[\"5평균\"] - train_close[\"10평균\"]\n",
    "\n",
    "    ## 표준화 + 모델 진행\n",
    "    # StandardScaler객체 생성\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    #scaler용 input 생성\n",
    "    input = train_close[['5_10평균']]\n",
    "\n",
    "    # StandardScaler 로 데이터 셋 변환. fit( ) 과 transform( ) 호출.  \n",
    "    scaler.fit(input)\n",
    "    train_scaled = scaler.transform(input)\n",
    "    train_close['5_10평균'] = train_scaled\n",
    "\n",
    "    # 데이터 전처리\n",
    "    # 변수 x\n",
    "    dfx = train_close[['5_10평균']]\n",
    "    # 정답 y\n",
    "    dfy = train_close[['종가']]\n",
    "\n",
    "    X = dfx.values.tolist()\n",
    "    y = dfy.values.tolist()\n",
    "\n",
    "    ###  10일 동안의 OHLVC 데이터로 다음 날의 종가를 예측\n",
    "    \n",
    "    window_size = 15\n",
    "\n",
    "    data_X = []\n",
    "    data_y = []\n",
    "    for i in range(len(y) - window_size):\n",
    "        _X = X[i : i + window_size] # 다음 날 종가(i+windows_size)는 포함되지 않음\n",
    "        _y = y[i + window_size]     # 다음 날 종가\n",
    "        data_X.append(_X)\n",
    "        data_y.append(_y)\n",
    "    print(_X, \"->\", _y)\n",
    "\n",
    "\n",
    "    ####### train / test 분리\n",
    "\n",
    "    print('전체 데이터의 크기 :', len(data_X), len(data_y))\n",
    "    \n",
    "    train_size = int(len(data_y) * 0.8)\n",
    "    train_X = np.array(data_X[0 : train_size])\n",
    "    train_y = np.array(data_y[0 : train_size])\n",
    "\n",
    "    test_size = len(data_y) - train_size\n",
    "    test_X = np.array(data_X[train_size : len(data_X)])\n",
    "    test_y = np.array(data_y[train_size : len(data_y)])\n",
    "\n",
    "    print('훈련 데이터의 크기 :', train_X.shape, train_y.shape)\n",
    "    print('테스트 데이터의 크기 :', test_X.shape, test_y.shape)\n",
    "\n",
    "    # 모델 학습\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=20, activation='relu', return_sequences=True, input_shape=(15, 1)))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LSTM(units=20, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(units=1))\n",
    "    model.summary()\n",
    "\n",
    "    # 모델 학습\n",
    "    predictions =[]\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    model.fit(train_X, train_y, epochs=70, batch_size=30)\n",
    "    \n",
    "    predictions.append(model.predict(test_X)) # 예측\n",
    "    \n",
    "    # 최종 데이터프레임\n",
    "    final_df = final_df.append({'종목코드': code, 'final_return': predictions}, ignore_index=True)\n",
    "\n",
    "\n",
    "final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:59<00:00, 16.69it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>종목코드</th>\n",
       "      <th>final_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A060310</td>\n",
       "      <td>일자\n",
       "2021-08-24   -144.5\n",
       "2021-08-25   -120.5\n",
       "202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A095570</td>\n",
       "      <td>일자\n",
       "2021-08-24   -101.0\n",
       "2021-08-25   -121.0\n",
       "202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A006840</td>\n",
       "      <td>일자\n",
       "2021-08-24   -1095.0\n",
       "2021-08-25    -920.0\n",
       "2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A054620</td>\n",
       "      <td>일자\n",
       "2021-08-24   -1065.0\n",
       "2021-08-25   -1235.0\n",
       "2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A265520</td>\n",
       "      <td>일자\n",
       "2021-08-24   -1020.0\n",
       "2021-08-25    -765.0\n",
       "2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>A189980</td>\n",
       "      <td>일자\n",
       "2021-08-24   -264.0\n",
       "2021-08-25   -262.0\n",
       "202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>A000540</td>\n",
       "      <td>일자\n",
       "2021-08-24   -94.0\n",
       "2021-08-25   -74.5\n",
       "2021-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>A003280</td>\n",
       "      <td>일자\n",
       "2021-08-24     0.0\n",
       "2021-08-25     0.0\n",
       "2021-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>A037440</td>\n",
       "      <td>일자\n",
       "2021-08-24   -219.0\n",
       "2021-08-25   -203.0\n",
       "202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>A238490</td>\n",
       "      <td>일자\n",
       "2021-08-24   -458.0\n",
       "2021-08-25   -354.0\n",
       "202...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         종목코드                                       final_return\n",
       "0     A060310  일자\n",
       "2021-08-24   -144.5\n",
       "2021-08-25   -120.5\n",
       "202...\n",
       "1     A095570  일자\n",
       "2021-08-24   -101.0\n",
       "2021-08-25   -121.0\n",
       "202...\n",
       "2     A006840  일자\n",
       "2021-08-24   -1095.0\n",
       "2021-08-25    -920.0\n",
       "2...\n",
       "3     A054620  일자\n",
       "2021-08-24   -1065.0\n",
       "2021-08-25   -1235.0\n",
       "2...\n",
       "4     A265520  일자\n",
       "2021-08-24   -1020.0\n",
       "2021-08-25    -765.0\n",
       "2...\n",
       "...       ...                                                ...\n",
       "1995  A189980  일자\n",
       "2021-08-24   -264.0\n",
       "2021-08-25   -262.0\n",
       "202...\n",
       "1996  A000540  일자\n",
       "2021-08-24   -94.0\n",
       "2021-08-25   -74.5\n",
       "2021-...\n",
       "1997  A003280  일자\n",
       "2021-08-24     0.0\n",
       "2021-08-25     0.0\n",
       "2021-...\n",
       "1998  A037440  일자\n",
       "2021-08-24   -219.0\n",
       "2021-08-25   -203.0\n",
       "202...\n",
       "1999  A238490  일자\n",
       "2021-08-24   -458.0\n",
       "2021-08-25   -354.0\n",
       "202...\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### 0725 ver --- 이거로 진행\n",
    "# train 데이터에 존재하는 독립적인 종목코드 추출\n",
    "unique_codes = train['종목코드'].unique()\n",
    "date = train['일자'].unique()\n",
    "\n",
    "# 저장할 데이터 프레임\n",
    "final_df = pd.DataFrame(columns=['종목코드'])\n",
    "final_df = final_df.set_index(date)\n",
    "\n",
    "\n",
    "for code in tqdm(unique_codes):\n",
    "#code = \"A103840\"\n",
    "# # 이동평균선 간격 데이터 생성\n",
    "    train_close = train[train['종목코드'] == code][['종목코드','일자', '종가']]\n",
    "    train_close['일자'] = pd.to_datetime(train_close['일자'], format='%Y%m%d')\n",
    "    train_close.set_index('일자', inplace=True)\n",
    "\n",
    "    # 이동평균선 (5/10/20/60)\n",
    "    train_close[\"5평균\"] = train_close['종가'].rolling(window=5).mean()\n",
    "    train_close[\"10평균\"] = train_close['종가'].rolling(window=10).mean()\n",
    "    train_close[\"20평균\"] = train_close['종가'].rolling(window=20).mean()\n",
    "    train_close[\"60평균\"] = train_close['종가'].rolling(window=60).mean()\n",
    "\n",
    "    # 등락폭\n",
    "    #train_close[\"shift\"] = train_close[\"종가\"].shift(1)\n",
    "    #train_close[\"등락폭\"] = (train_close[\"종가\"] - train_close[\"shift\"])\n",
    "    #train_close[\"등락비율\"] = ((train_close[\"종가\"] - train_close[\"shift\"])/train_close[\"shift\"])\n",
    "    #train_close.drop(\"shift\", axis=1,inplace=True)   \n",
    "    \n",
    "    #이동평균선 NaN 값 삭제\n",
    "    train_close.dropna(axis=0,inplace=True)\n",
    "\n",
    "    # 추세선 내부 간격 함수\n",
    "    # 1 _ 5평균 - 10평균\n",
    "    #train_close['5_10평균'] = train_close[\"5평균\"] - train_close[\"10평균\"]\n",
    "    train_close['5_10평균'] = train_close[\"5평균\"] - train_close[\"10평균\"]\n",
    "\n",
    "    # 2 _ 5평균 - 20평균\n",
    "    #train_close['5_20평균'] = train_close[\"5평균\"]-train_close[\"20평균\"]\n",
    "    \n",
    "    # 3 _ 5평균 - 60평균\n",
    "    #train_close['5_60평균'] = train_close[\"5평균\"]-train_close[\"60평균\"]\n",
    "    \n",
    "    # 4 _ 10평균 - 20평균\n",
    "    #train_close['10_20평균'] = train_close[\"10평균\"]-train_close[\"20평균\"]\n",
    "\n",
    "    # 5 _ 10평균 - 60평균\n",
    "    #train_close['10_60평균'] = train_close[\"10평균\"]-train_close[\"60평균\"]\n",
    "\n",
    "    # 6 _ 20평균 - 60평균\n",
    "    #train_close['20_60평균'] = train_close[\"20평균\"]-train_close[\"60평균\"]\n",
    "\n",
    "    # 학습 데이터프레임\n",
    "    for i in range(len(train_close)):\n",
    "        train_close['5_10평균'][i]\n",
    "\n",
    "\n",
    "    final_df = final_df.append({'종목코드': code, 'final_return': train_close['5_10평균']}, ignore_index=True)\n",
    "    final_df = final_df.merge([final_df,],on=final_df.index)\n",
    "\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "일자\n",
       "2021-08-24   -144.5\n",
       "2021-08-25   -120.5\n",
       "2021-08-26    -76.5\n",
       "2021-08-27      8.5\n",
       "2021-08-30     63.0\n",
       "              ...  \n",
       "2023-05-23     15.5\n",
       "2023-05-24     21.0\n",
       "2023-05-25     17.0\n",
       "2023-05-26     78.0\n",
       "2023-05-30    140.5\n",
       "Name: 5_10평균, Length: 435, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.iloc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://wikidocs.net/173005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
